## Hongsuk Benjamin Choi
![image](./images/hongsukchoi_photo_0.png){: style="float: left; width: 175px; height: 225px; margin-right: 1em; margin-top: 0.5em  "}

### ML/CV Researcher
I am currently an ML/CV Researcher at Samsung AI center, New York. Please refer to my CV for more information! **[CV](CV_Hongsuk_Choi_Feb2023.pdf)**

Email: **redstonepo@gmail.com** \
[Google Scholar](https://scholar.google.com/citations?user=CZbowncAAAAJ&hl=en) \
[Linkedin](https://www.linkedin.com/in/hongsuk-choi-6b081a143/) \
[Github](https://github.com/hongsukchoi)

        
<br>

### Research Interests
3D comptuer vision related to motion capture, human hand &  body reconstruction, and robotics perception.

<br>

### Publications (Selected)


<!--Rethinking-->
<p>
<img src="images/Pretrain_ICLR2023.png" align="left" style="width:360px; height:200px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:120px;">
<b><font color="0066CC"> Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation </font></b>
<br>
<b>Hongsuk Choi (*)</b>, Hyeongjin Nam (*), Taeryung Lee, Gyeongsik Moon, Kyoung Mu Lee <b>(* equal contribution)</b>
<br>
In <b>ICLR 2023</b>
<br>
[ARXIV] 
<!-- [<a href="https://arxiv.org/abs/2210.00627">ARXIV</a>] [<a href="https://youtu.be/9-hfGf7dRw4">VIDEO</a>] -->
</div>
</p>

<br>

<!--MonoNHR-->
<p>
<img src="images/MonoNHR_3DV2022.gif" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:100px;">

<b><font color="0066CC"> MonoNHR: Monocular Neural Human Renderer </font></b>
<br>
<b>Hongsuk Choi (*)</b>, Gyeongsik Moon (*), Matthieu Armando, Vincent Leroy, Kyoung Mu Lee, Gregory Rogez <b>(* equal contribution)</b>
<br>
In <b>3DV 2022</b>
<br>
[<a href="https://arxiv.org/abs/2210.00627">ARXIV</a>] [<a href="https://youtu.be/9-hfGf7dRw4">VIDEO</a>]
</div>
</p>

<br>

<!--HandOccNet-->
<p>
<img src="images/HandOccNet_CVPR2022.png" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:100px;">

<b> <font color="0066CC"> HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network </font> </b>
<br>
JoonKyu Park (*), Yeonguk Oh (*), Gyeongsik Moon (*), <b>Hongsuk Choi</b>, Kyoung Mu Lee <b>(* equal contribution)</b>
<br>
In <b>CVPR 2022</b>
<br>
[<a href="https://arxiv.org/abs/2203.14564">ARXIV</a>] [<a href="https://github.com/namepllet/HandOccNet">CODE</a>]
</div>
</p>


<br>

<!--3DCrowdNet-->
<p>
<img src="images/3DCrowdNet_CVPR2022.png" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:100px;">

<b> <font color="0066CC"> Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes </font> </b>
<br>
<b>Hongsuk Choi</b>, Gyeongsik Moon, JoonKyu Park, Kyoung Mu Lee
<br>
In <b>CVPR 2022</b>
<br>
[<a href="https://arxiv.org/abs/2104.07300">ARXIV</a>] [<a href="https://github.com/hongsukchoi/3DCrowdNet_RELEASE">CODE</a>]
</div>
</p>


<br>

<!--Hand4Whole-->
<p>
<img src="images/Hand4Whole_CVPRW2022.png" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:100px;">

<b> <font color="0066CC"> Accurate 3D Hand Pose Estimation for Whole-Body 3D Human Mesh Estimation </font> </b>
<br>
Gyeongsik Moon, <b>Hongsuk Choi</b>, Kyoung Mu Lee
<br>
In <b>CVPRW 2022</b>
<br>
[<a href="https://arxiv.org/abs/2011.11534">ARXIV</a>] [<a href="https://youtu.be/Ym_CH8yxBso">VIDEO</a>] [<a href="https://github.com/mks0601/Hand4Whole_RELEASE">CODE</a>]
</div>
</p>


<br>

<!--NeuralAnnot-->
<p>
<img src="images/NeuralAnnot_CVPRW2022.png" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:120px;">

<b> <font color="0066CC"> NeuralAnnot: Neural Annotator for 3D Human Mesh Training Sets </font> </b>
<br>
Gyeongsik Moon, <b>Hongsuk Choi</b>, Kyoung Mu Lee
<br>
In <b>CVPRW 2022</b>
<br>
[<a href="https://arxiv.org/abs/2011.11232">ARXIV</a>] [<a href="https://github.com/mks0601/NeuralAnnot_RELEASE">HOMEPAGE</a>]
</div>
</p>


<br>

<!--TCMR-->
<p>
<img src="images/TCMR_CVPR2021.gif" align="left" style="width:360px; height:180px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:100px;">

<b> <font color="0066CC"> Beyond Static Features for Temporally Consistent 3D Human Pose and Shape from a Video </font> </b>
<br>
<b>Hongsuk Choi</b>, Gyeongsik Moon, Ju Yong Chang, Kyoung Mu Lee
<br>
In <b>CVPR 2021</b>
<br>
[<a href="https://arxiv.org/abs/2011.08627">ARXIV</a>] [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Beyond_Static_Features_for_Temporally_Consistent_3D_Human_Pose_and_CVPR_2021_paper.pdf">PDF</a>] [<a href="https://github.com/hongsukchoi/TCMR_RELEASE">CODE</a>] [<a href="https://www.youtube.com/watch?v=WB3nTnSQDII">VIDEO</a>]
</div>
</p>


<br>

<!--Pose2Mesh-->
<p>
<img src="images/Pose2Mesh_ECCV2020.png" align="left" style="width:360px; height:200px; margin-right:10px;  vertical-align=middle;">
<div style="margin-bottom:140px;">

<b> <font color="0066CC"> Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose </font> </b>
<br>
<b>Hongsuk Choi (*)</b>,  Gyeongsik Moon (*) , Kyoung Mu Lee <b>(* equal contribution)</b>
<br>
In <b>ECCV 2020</b>
<br>
[<a href="https://arxiv.org/abs/2008.09047">ARXIV</a>] [<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123520749.pdf">PDF</a>] [<a href="https://github.com/hongsukchoi/Pose2Mesh_RELEASE">CODE</a>] [<a href="https://youtu.be/utaHeByNauc">VIDEO</a>]
</div>
</p>


<br>    


### Honors

<p align="middle">
<img src="images/SNU.png" width="100px" height="100px">
</p>
<p align="center">
<b>SNU Distinguished Master Dissertation Award</b> (2022)
</p>

<p align="middle">
<img src="images/3DPW_challenge_1st.png" width="240px" height="180px"><img src="images/3DPW_challenge_2nd.png" width="240px" height="180px">
</p>
<p align="center">
  <b>1st place</b> and <b>2nd place</b> at the <b>3D human pose estimation in the wild (3DPW) challenge</b> of a without association track in joint orientation and position metrics, respectively <br> (workshop in conjunction with <b>ECCV 2020</b>)
</p>

<p align="middle">
<img src="images/Qualcomm.png" width="225px" height="80px">
</p>
<p align="center">
<b>Qualcomm IT Tour 2019 presentation competition 1st place</b> (2019)
</p>

<br>

### Service
* A Reviewer for computer vision and machine learning conferences 
\- <b>CVPR</b>, <b>ICCV</b>, <b>ECCV</b> and others
* A Reviewer for computer vision journals
\- <b>TPAMI</b>, IEEE TIP and others

<br>

### Experience
<p align="middle">
<img src="images/sra.png" width="250px" height="50px">
</p>
<p align="center">
  <b>ML research engineer</b>, <b>Samsung Research America</b>, New York, NY, USA <br> (Jun. 2022 - present)
</p>

<p align="middle">
<img src="images/Naver.png" width="280px" height="50px">
</p>
<p align="center">
  <b>Visiting Researcher</b>, <b>Naver CLOVA AI Lab</b>, Seoul, Korea <br> (Mar. 2022 - May. 2022)
</p>

<p align="middle">
<img src="images/NLE.jpg" width="230px" height="50px">
</p>
<p align="center">
  <b>Research Intern</b>, <b>Naver Labs Europe (NLE)</b>, Grenoble, France <br> (April. 2021 - Oct. 2021)
</p>


<p align="middle">
<img src="images/SNU.png" width="100px" height="100px">
</p>
<p align="center">
  <b>M.S.</b>, ECE, <b>Seoul National University (SNU)</b>, Seoul, Korea <br> (Mar. 2020 - Feb. 2022)
</p>


<p align="middle">
<img src="images/roka.png" swidth="300px" height="100px">
</p>
<p align="center">
  <b>Repulic of Korea Airforce (ROKA)</b>, Gyeryong, Korea <br> (Mar. 2015 - Mar. 2017)
</p>

<p align="middle">
<img src="images/SNU.png" width="100px" height="100px">
</p>
<p align="center">
  <b>B.S.</b>, Business, CSE, <b>Seoul National University (SNU)</b>, Seoul, Korea <br> (Mar. 2013 - Feb. 2020)
</p>
